{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import to_categorical\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads an image and converts to a specd version and resize\n",
    "def get_image_value(path, dim):\n",
    "    img = image.load_img(path, target_size = dim)\n",
    "    img = image.img_to_array(img)\n",
    "\n",
    "    return img/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes a list of image paths and returns the np \n",
    "# array corresponding to each image.  It also takes the dim and \n",
    "# whether edge is specified in order to pass it to another \n",
    "# function to apply these parameters.  This function uses \n",
    "# get_image_value to perform these operations\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_img_array(img_paths, dim):\n",
    "    final_array = []\n",
    "\n",
    "    for path in tqdm(img_paths):\n",
    "        img = get_image_value(path, dim)\n",
    "        final_array.append(img)\n",
    "    \n",
    "    final_array = np.array(final_array)\n",
    "    return final_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a train - test - split\n",
    "def get_tts():\n",
    "\n",
    "    DIM =  (150,150) \n",
    "    np.random.seed(10) \n",
    "           \n",
    "    pistol_paths = [f'Separated/FinalImages/Pistol/{i}' for i in os.listdir('Separated/FinalImages/Pistol')] \n",
    "    pistol_labels = [1 for i in range(len(pistol_paths))]\n",
    "    \n",
    "    rifle_paths = [f'Separated/FinalImages/Rifle/{i}' for i in os.listdir('Separated/FinalImages/Rifle')] \n",
    "    rifle_labels = [2 for i in range(len(rifle_paths))]    \n",
    "    \n",
    "    neg_paths = [f'Separated/FinalImages/NoWeapon/{i}' for i in os.listdir('Separated/FinalImages/NoWeapon')]\n",
    "    np.random.shuffle(neg_paths)\n",
    "    \n",
    "    neg_paths = neg_paths[:len(pistol_paths)- 500]\n",
    "    neg_labels = [0 for i in range(len(neg_paths))]\n",
    "\n",
    "    np.random.shuffle(pistol_paths)\n",
    "    pistol_paths = pistol_paths[:len(rifle_paths)+150]\n",
    "    neg_paths = neg_paths[:len(rifle_paths)+150]\n",
    "\n",
    "    pistol_labels = [1 for i in range(len(pistol_paths))]\n",
    "    rifle_labels = [2 for i in range(len(rifle_paths))]\n",
    "    neg_labels = [0 for i in range(len(neg_paths))]\n",
    "    \n",
    "    paths = pistol_paths + rifle_paths + neg_paths\n",
    "    labels = pistol_labels + rifle_labels + neg_labels\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(paths, labels, stratify = labels, train_size = .90, random_state = 10)\n",
    "\n",
    "    new_x_train = get_img_array(x_train, DIM)\n",
    "    new_x_test = get_img_array(x_test, DIM)\n",
    "    \n",
    "    print('Train Value Counts')\n",
    "    print(pd.Series(y_train).value_counts())\n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "    print('Test Value Counts')\n",
    "    print(pd.Series(y_test).value_counts())\n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "    print('X Train Shape')\n",
    "    print(new_x_train.shape)\n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "    print('X Test Shape')\n",
    "    print(new_x_test.shape)\n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "    y_test = to_categorical(y_test)\n",
    "    y_train = to_categorical(y_train)\n",
    "    tts = (new_x_train, new_x_test, y_train, y_test)\n",
    "    \n",
    "    return tts\n",
    "\n",
    "x_train, x_test, y_train, y_test = get_tts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural network implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pickle, cv2\n",
    "\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras import regularizers\n",
    "\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, AveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates and compiles a CNN given an input dimention\n",
    "from telnetlib import SE\n",
    "\n",
    "def get_conv_model(dim = (150,150,3)):\n",
    "    input_shape = dim\n",
    "    act = 'relu'\n",
    "    drop = .25\n",
    "    kernel_reg = regularizers.l1(0.001)\n",
    "    optimizer = Adam(lr = 0.001)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, kernel_size=(3,3),activation=act, input_shape = input_shape, kernel_regularizer = kernel_reg, kernel_initializer = 'he_uniform',  padding = 'same', name = 'Input_Layer'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),  strides = (3,3)))\n",
    "    model.add(Conv2D(64, (3, 3), activation=act, kernel_regularizer = kernel_reg, kernel_initializer = 'he_uniform',padding = 'same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides = (3,3))) \n",
    "    model.add(Conv2D(128, (3, 3), activation=act, kernel_regularizer = kernel_reg, kernel_initializer = 'he_uniform',padding = 'same'))\n",
    "    model.add(Conv2D(128, (3, 3), activation=act, kernel_regularizer = kernel_reg, kernel_initializer = 'he_uniform',padding = 'same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides = (3,3))) \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu')) \n",
    "    model.add(Dense(64, activation='relu')) \n",
    "    model.add(Dense(32, activation='relu')) \n",
    "    model.add(Dropout(drop))\n",
    "    model.add(Dense(3, activation='softmax', name = 'Output_Layer'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer= optimizer, metrics = ['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "#model = get_conv_model(dim = (150,150,3))\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prevents overfitting and saves models every time the validation loss improves\n",
    "early_stopping = EarlyStopping(monitor='val_loss', verbose = 1, patience=10, min_delta = .0075)\n",
    "model_checkpoint = ModelCheckpoint('ModelWeights.h5', verbose = 1, save_best_only=True, monitor = 'val_loss')\n",
    "lr_plat = ReduceLROnPlateau(patience = 2, mode = 'min')\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 8\n",
    "model = get_conv_model()\n",
    "model_history = model.fit(x_train, y_train, batch_size = batch_size,epochs = epochs, \n",
    "     callbacks = [early_stopping, model_checkpoint, lr_plat], validation_data = (x_test, y_test), verbose= 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results on this training\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = model_history.history['acc']\n",
    "val_acc = model_history.history['val_acc']\n",
    "loss = model_history.history['loss']\n",
    "val_loss = model_history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy'), plt.grid()\n",
    "plt.legend(), plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss'), plt.grid()\n",
    "plt.legend(), plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_max_suppression(boxes, overlapThresh= .5):\n",
    "    '''This image was taken from PyImageSearch... again cannot thank that guy enough'''\n",
    "    # if there are no boxes, return an empty list\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "    # if the bounding boxes integers, convert them to floats --\n",
    "    # this is important since we'll be doing a bunch of divisions\n",
    "    if boxes.dtype.kind == \"i\":\n",
    "        boxes = boxes.astype(\"float\")\n",
    "    # initialize the list of picked indexes\t\n",
    "    pick = []\n",
    "    # grab the coordinates of the bounding boxes\n",
    "    x1, y1, x2, y2 = boxes[:,0], boxes[:,1], boxes[:,2], boxes[:,3]    \n",
    "    # compute the area of the bounding boxes and sort the bounding\n",
    "    # boxes by the bottom-right y-coordinate of the bounding box\n",
    "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    idxs = np.argsort(y2)\n",
    "\n",
    "    # keep looping while some indexes still remain in the indexes\n",
    "    # list\n",
    "    while len(idxs) > 0:\n",
    "        # grab the last index in the indexes list and add the\n",
    "        # index value to the list of picked indexes\n",
    "        last = len(idxs) - 1\n",
    "        i = idxs[last]\n",
    "        pick.append(i)\n",
    "        # find the largest (x, y) coordinates for the start of\n",
    "        # the bounding box and the smallest (x, y) coordinates\n",
    "        # for the end of the bounding box\n",
    "        xx1, yy1, xx2, yy2 = np.maximum(x1[i], x1[idxs[:last]]), np.maximum(y1[i], y1[idxs[:last]]), np.minimum(x2[i], x2[idxs[:last]]), np.minimum(y2[i], y2[idxs[:last]])\n",
    "        # compute the width and height of the bounding box\n",
    "        w, h = np.maximum(0, xx2 - xx1 + 1), np.maximum(0, yy2 - yy1 + 1)\n",
    "        # compute the ratio of overlap\n",
    "        overlap = (w * h) / area[idxs[:last]]\n",
    "        # delete all indexes from the index list that have\n",
    "        idxs = np.delete(idxs, np.concatenate(([last],\n",
    "            np.where(overlap > overlapThresh)[0])))\n",
    "    # return only the bounding boxes that were picked using the\n",
    "    # integer data type\n",
    "    return pick\n",
    "\n",
    "\n",
    "def get_img_prediction_bounding_box(path, model, dim):\n",
    "    '''This function will create a bounding box over what it believes is a weapon given the image path, dimensions, and model used to detect the weapon.  Dimensions can be found within the Var.py file.  This function is still being used as I need to apply non-max suppresion to create only one bounding box'''\n",
    "    img = get_image_value(path, dim)   \n",
    "    img = img.reshape(1, img.shape[0], img.shape[1], 3)\n",
    "    pred = model.predict(img)[0]\n",
    "    category_dict = {0: 'No Weapon', 1: 'Handgun', 2: 'Rifle'}\n",
    "    cat_index = np.argmax(pred)\n",
    "    cat = category_dict[cat_index]\n",
    "    print(f'{path}\\t\\tPrediction: {cat}\\t{int(pred.max()*100)}% Confident')\n",
    "\n",
    "    #speed up cv2\n",
    "    cv2.setUseOptimized(True)\n",
    "    cv2.setNumThreads(10) #change depending on your computer\n",
    "    img = cv2.imread(path)\n",
    "    clone = img.copy() \n",
    "    clone2 = img.copy()\n",
    "    ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()\n",
    "    ss.setBaseImage(img)\n",
    "    ss.switchToSelectiveSearchFast()\n",
    "\n",
    "    rects = ss.process() \n",
    "    windows = []\n",
    "    locations = []\n",
    "    print(f'Creating Bounding Boxes for {path}')\n",
    "    for x, y, w,h in rects[:1001]: \n",
    "        startx, starty, endx, endy = x, y, x+w, y+h \n",
    "        roi = img[starty:endy, startx:endx]\n",
    "        roi = cv2.resize(roi, dsize =dim, interpolation = cv2.INTER_CUBIC)\n",
    "        windows.append(roi)\n",
    "        locations.append((startx, starty, endx, endy))\n",
    "    windows = np.array(windows)\n",
    "    windows = windows.reshape(windows.shape[0], windows.shape[1], windows.shape[2], 3)\n",
    "    windows = np.array(windows)\n",
    "    locations = np.array(locations)\n",
    "    predictions = model.predict(windows)\n",
    "    nms = non_max_suppression(locations)\n",
    "    bounding_cnt = 0\n",
    "    for idx in nms:\n",
    "        if np.argmax(predictions[idx]) != cat_index: \n",
    "            continue\n",
    "        startx, starty, endx, endy = locations[idx]\n",
    "        cv2.rectangle(clone, (startx, starty), (endx, endy), (0,0,255), 2)\n",
    "        text = f'{category_dict[np.argmax(predictions[idx])]}: {int(predictions[idx].max()*100)}%'\n",
    "        cv2.putText(clone, text, (startx, starty+15), cv2.FONT_HERSHEY_SIMPLEX, .5, (0,255,0),2)\n",
    "        bounding_cnt += 1\n",
    "\n",
    "    if bounding_cnt == 0: \n",
    "        pred_idx= [idx for idx, i in enumerate(predictions) if np.argmax(i) == cat_index]\n",
    "        cat_locations = np.array([locations[i] for i in pred_idx])\n",
    "        nms = non_max_suppression(cat_locations)\n",
    "        if len(nms)==0:\n",
    "            cat_predictions = predictions[:,cat_index]\n",
    "            pred_max_idx = np.argmax(cat_predictions)\n",
    "            pred_max = cat_predictions[pred_max_idx]\n",
    "            pred_max_window = locations[pred_max_idx]\n",
    "            startx, starty, endx, endy = pred_max_window\n",
    "            cv2.rectangle(clone, (startx, starty), (endx, endy),  (0,0,255),2)\n",
    "            text = f'{category_dict[cat_index]}: {int(pred_max*100)}%'\n",
    "            cv2.putText(clone, text, (startx, starty+15), cv2.FONT_HERSHEY_SIMPLEX, .5, (0,255,0),2)\n",
    "        for idx in nms: \n",
    "            startx, starty, endx, endy = cat_locations[idx]\n",
    "            cv2.rectangle(clone, (startx, starty), (endx, endy), (0,0,255), 2)\n",
    "            text = f'{category_dict[np.argmax(predictions[pred_idx[idx]])]}: {int(predictions[pred_idx[idx]].max()*100)}%'\n",
    "            cv2.putText(clone, text, (startx, starty+15), cv2.FONT_HERSHEY_SIMPLEX, .5, (0,255,0),2)        \n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "    cv2.imshow(f'Test', np.hstack([clone, clone2]))\n",
    "    cv2.waitKey(0)\n",
    "    ss.clear()\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NORMAL MODEL\n",
    "dim = (150, 150, 3)    \n",
    "normal_model = get_conv_model(dim)\n",
    "normal_model.load_weights('ModelWeights.h5') #path to the model weights\n",
    "test_folder = 'Tests' #folder where you will put your images to test\n",
    "predictions = []\n",
    "\n",
    "for idx, i in enumerate([i for i in os.listdir(test_folder) if i != 'ipynb_checkpoints']):\n",
    "    img_path = f'{test_folder}/{i}'\n",
    "    pred = get_img_prediction_bounding_box(img_path, normal_model, dim = (150,150))\n",
    "    predictions.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Live demonstration\n",
    "\n",
    "vid = cv2.VideoCapture(0)\n",
    "\n",
    "while(True):\n",
    "\n",
    "    ret, frame = vid.read()\n",
    "\n",
    "    cv2.imshow(\"frame\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fd516890b92a1dfcd702a7a0a6d0d1af4dddef2e3a72e9b797c84d0fe79e62bd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
