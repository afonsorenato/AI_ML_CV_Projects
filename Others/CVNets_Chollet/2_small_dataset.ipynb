{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategies\n",
    "# 1 - Train model from scratch\n",
    "# 2 - Feature extraction using pre-trained models\n",
    "# 3 - Fine tunning pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "train_dir = \"Dataset/train/\"\n",
    "test_dir = \"Dataset/test/\"\n",
    "validation_dir = \"Dataset/validation/\"\n",
    "\n",
    "train_rice_dir = os.path.join(train_dir, 'rice')\n",
    "validation_rice_dir = os.path.join(validation_dir, 'rice')\n",
    "test_rice_dir = os.path.join(test_dir, 'rice')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# Added a dropout layer\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', \n",
    "                optimizer=optimizers.RMSprop(lr=1e-4), \n",
    "                metrics=['acc'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Added data augmentation: only the train dataset is augmented!\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=180, \n",
    "    width_shift_range=0.25,\n",
    "    height_shift_range=0.25, \n",
    "    shear_range=0.25,\n",
    "    zoom_range=0.1, \n",
    "    horizontal_flip=True, \n",
    "    fill_mode='nearest')\n",
    "\n",
    "\n",
    "# Pre-process the dataset: rescale to 1 channel and\n",
    "target_size=(150, 150)\n",
    "batch_size = 3\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory( \n",
    "        train_dir, \n",
    "        target_size=target_size, \n",
    "        batch_size=batch_size, \n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_dir, \n",
    "    target_size = target_size, \n",
    "    batch_size=batch_size, \n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit_generator(train_generator, \n",
    "    steps_per_epoch=20, \n",
    "    epochs=40, \n",
    "    validation_data=validation_generator,  \n",
    "    validation_steps=50)\n",
    "\n",
    "model.save('rice_tuna_tomato_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results on this training\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(), plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend(), plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "from keras.preprocessing import image\n",
    "\n",
    "img_path = \"Dataset/train/rice/1413412efd - CÃ³pia (2).jpg\"\n",
    "img = image.load_img(img_path, target_size=(150, 150))\n",
    "x = image.img_to_array(img)\n",
    "x = x.reshape((1,) + x.shape)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=180, width_shift_range=0.25,\n",
    "    height_shift_range=0.25, shear_range=0.25,\n",
    "    zoom_range=0.1, horizontal_flip=True, fill_mode='nearest')\n",
    "\n",
    "i = 0\n",
    "for batch in datagen.flow(x, batch_size=1):\n",
    "    plt.figure(i)\n",
    "    imgplot = plt.imshow(image.array_to_img(batch[0]))\n",
    "    i += 1\n",
    "    if i % 4 == 0:\n",
    "        break\n",
    "plt.show()  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One might train a network on ImageNet (where classes are mostly animals and everyday objects) and then repurpose this trained network for something as remote as identifying furniture items in images. Such portability of learned features across different problems is a key advantage of deep learning compared to many older, shallow-learning approaches, and it makes deep learning very effective for small-data problems.\n",
    "\n",
    "Dataset --> ImageNet\n",
    "\n",
    "Model / architecture --> VGG16\n",
    "\n",
    "\n",
    "There are two ways to use a pretrained network: feature extraction and fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fd516890b92a1dfcd702a7a0a6d0d1af4dddef2e3a72e9b797c84d0fe79e62bd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
